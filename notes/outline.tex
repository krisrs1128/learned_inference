\documentclass[11pt]{article}
\usepackage{graphicx,amsmath,amssymb}
\usepackage{outlines}
\usepackage{enumitem}
\setenumerate[1]{label=\Roman*.}
\setenumerate[2]{label=\Alph*.}
\setenumerate[3]{label=\roman*.}
\setenumerate[4]{label=\alph*.}


\title{}
\author{Kris Sankaran}
\begin{document}
\maketitle

\begin{outline}
\1 Two concrete examples
  \2 Collaborator thinks that mixing between cell types might be related to
  survival in cancer
  \2 Epidemiologist things that certain kinds of built environment / pollution
  are associated with disease
  \2 Traditionally: derive features manually
    \3 Define tumor invasion scores
    \3 Label polluted sites
  \2 Limits of traditional / the current frontier
    \3 Manually extracting features is a time-consuming process
    \3 Even if you had the patience to extract features, there is always the
    potential that you are missing some features that are relevant
\1 Associated abstraction
  \2 Problem definition
    \3 We want to perform formal inference on features / encodings that were
    algorithmically derived, where the encoder is treated as a black box
      \4 $X \in \mathbb{R}^{n \times p}$ are original features. Likely
      not meaningful, like the raw pixel values of an image, or vectorized
      adjacency matrix of a graph.
      \4 $z\left(\cdot; \hat{\eta}\left(X\right)\right) : \mathbb{R}^{p} \to
      \mathbb{R}^{k}$ is a learned encoder, with parameters $\eta$. Possible to
      also learn encoder in a supervised way: $\eta\left(X, y\right)$.
      \4 Denote $z^{\ast} = z\left(x^{\ast}; \hat{\eta}\left(X\right)\right)$ or
      $z_{i} = z\left(x_{i}; \hat{\eta}\left(X\right)\right)$ are encodings when
      you apply to new (or old) data $x^\ast$ or $x_{i}$, respectively.
      \4 We want something like a variable importance / stability score for the
      $k^{th}$ coordinate of $z$, with respect to the outcome $y$ accounting for
      the fact that $z$ was learned in a more complex way
    \3 We want (something like?) FDR control guarantees: If we collected a new
    dataset, and derived a new set of features from the blackbox, then the new
    set of significant learned features should be very related to those learned
    originally
      \4 FDR control isn't the correct notion, however, because we can't simply
      call a feature a false positive or false negative feature.
      \4 To the extent that there is any signal relating $X$ to $y$, then each
      of the coordinates of $z$ is likely to exhibit some relationship. As in
      the PCA analogy, even when all the coordinates are in principle truly
      related to the response, some of the coordinates are going to be targeted
      for interpretation (people come up with a story to interpret different PCA
      axes after the fact). We want to provide information that helps temper or
      strengthen those downstream interpretations.
    \3 We want to evaluate the stability of learned features from sample to
    population
  \2 Analogy: performing hypothesis tests on SPLS / PCA features derived from a
  large table.
    \3 The main difference now is that we'll work with features are derived from
    more complex data, which are not amenable to linear reductions: images and
    graphs.
\1 Related literature
  \2 What have people done, and how we're different
    \3 We are linked to literature on interpretability of black box models
      \4 Both they and us want to leverage newer, less structured in scientific
      applications
      \4 More than equipping people with new tools for interacting with
      encodings, we want to provide mechanisms for inference
      \4 It's important for us that we provide quantitative guidance about the
      reproducibility of a (blackbox analysis)
      \4 Example work: look up references in Raghu and Schmidt section 7
    \3 We are linked to literature on computational inference in
    high-dimensional models
      \4 Our encoders will map raw data into high-dimensional spaces, and we
      will need to screen lots of candidate features in order to find a few that
      are really worth following-up on, scientifically
      \4 Unlike that work, however, we're not going to assume that the features
      are given to us
      \4 Example work: stability selection, knockoffs, post-selection inference,
      split sample inference
\1 Contributions of this paper
  \2 Warning vs. reassurance: the features we learn from run to another are
  similar / different
    \3 in case different, here are some ways you can consolidate them
    \3 Quantification of scale of randomness driven by data vs. algorithm
  \2 Familiarity vs. surprise: features used after trying to optimize some
  metric aren't / are okay to use in inferential procedures
  \2 Natural computational speedups, and their validity in this setting
  (positive or negative result)
  \2 Conceptual overview of an increasingly common task in statistical
  analysis, along with implementation for others to follow along
\end{outline}

\section{Background}

\begin{outline}
\1 Intro
  \2 We draw on ideas from both computational inference and deep feature
  learning
  \2 Also leverage methods from multiview data analysis, since we're going to
  want to measure the similarity of encoding functions across multiple runs

\1 Stability
  \2 references: Yu's Tukey Lecture, Stability Selection

\1 Feature learning
  \2 Image autoencoders. Will encode on subtiles, and summarize using average
  position of a random selection of subtiles.
    \3 references:
  \2 CNNs
    \3 references:
  \2 Graph autoencoders
    \3 references:

\1 Multiview
  \2 Why is it necessary?
    \3 The encoders we learn from one sample to another will exhibit variation
      \4 In fact, even on the same sample, we may learn different encoders, just
      from randomness in the initialization
    \3 Multiview methods give us a way of quantifying the variation across
    learned functions
  \2 Transition, these are the methods that we find useful
  \2 RV coefficient
    \3 A measure of the similarity between two tables
    \3 Write the formula, (tk this is a random guess)
    \begin{align}
      RV\left(X, Y\right) &= \frac{tr\left(X^T Y\right)}{\|X\|_{F}\|Y\|_{F}}
    \end{align}
    \3 geometric interpretation: it's the angle between tables, viewed in an
    inner product space induced by the trace (?)
    \3 reference: Holmes and Josse
  \2 Multi-CCA
    \3 RV coefficient gives us a measure of similarity between encodings on a
    pairwise level, but what can we say when there are many runs to compare?
  \2 Nonlinear procrustes
    \3 Multi-CCA is nice, but what happens if linear correlation is too
    restricted?
\end{outline}

\section{Methodology}

\begin{outline}
\1 Establish notation
\1 stability selection of learned features (abstraction)
  \2 Working with a single feature extractor
    \3 This is not the focus of the paper, but it helps us ramp up to the real
    problem
    \3 Referring to response
      \4 Split the data
      \4 Learn features using one half
      \4 In theory, could perform stability selection on
    \3 Not referring to response
      \4 Use full data
      \4 Learn features on all, then perform selection
  \2 Consolidating multiple feature extractors
    \3 Limitation of previous approach: No sense of how reproducible the
    previous feature learner will be
    \3 Approach to consolidation
      \4 Create bootstrap samples in advance (possibly after having split, if feature learning refers to all y)
      \4 Learn feature learners using each of these datasets
      \4 Consolidate the learned features using one of the multiview methods above
      \4 Perform stability selection on entire dataset, after encoding using the consolidated features
\1 Scalable approximations
  \2 Challenge: learning each feature extractor can be very time consuming
  \2 Approach using coresets
  \2 Approach using fine-tuning
  \2 Question for simulation: What is the computation / inference trade-off?
\1 Visualization
  \2 Single encoding
    \3 Linked brushing to see the raw tiles associated with each type of encoding
  \2 Consolidated features
    \3 Project onto the multiview feature space, and look at point clouds. Each
    cloud is from one sample, across all the bootstrap samples.
\end{outline}

\section{Simulations}

\begin{outline}
  \1 Validity (single learner)
    \2 Description of goals
    \2 Data generation
    \2 Mention of which methods are applied, with what parameters
    \2 Figure summarizing results
      \3 Axes labels
      \3 Marks?
    \2 Takeaways from figure
  \1 Power analysis (single learner)
    \2 Describe goal for this simulation
    \2 Somewhat complex, since features are not defined in advance
    \2 Approach: How are features correlated with known factors of variation
    \2 Data generation
    \2 Which methods are applied, with what parameters
    \2 Figure summarizing results
      \3 Axes labels
      \3 Marks?
      \3 panels?
    \2 Takeaways from figure
  \1 Stability across learners
    \2 Describe goal for this simulation
    \2 Simulation setup
      \3 Explain similarities and differences from previous approach
      \3 Validity
      \3 Power
  \1 Computational approximations
    \2 Describe goal for this simulation
    \2 How much less diverse are the learned encodings?
    \2 Simulation setup
    \2 Figure explaining results
    \2 Takeaways from figure
  \1 Algorithmic vs. data-driven randomness
    \2 Describe goal for this simulation
    \2 Simulation setup
    \2 Figure explaining results
    \2 Takeaways from figure
\end{outline}

\section{Data analyses}

\begin{outline}
  \1 Introduction
    \2 Want to illustrate these ideas on a real problem
      \3 Link it back ot the illustrative example in the introduction
    \2 Description of the data
      \3 MIBI-TOF, or Imaging Cytof data
  \1 Goal of the study
    \2 How are spatial features related to survival in breast cancer?
    \2 Notion of tumor invasion and heterogeneity
\end{outline}

\section{Discussion and conclusions}

\begin{outline}
  \1 Main takeaways from this work
    \2 Warning vs. reassurance: the features we learn from run to another are
    similar / different
      \3 in case different, here are some ways you can consolidate them
      \3 Quantification of scale of randomness driven by data vs. algorithm
    \2 Familiarity vs. surprise: features used after trying to optimize some
    metric aren't / are okay to use in inferential procedures
    \2 Natural computational speedups, and their validity in this setting
    (positive or negative result)
    \2 Conceptual overview of an increasingly common task in statistical
    analysis, along with implementation for others to follow along
  \1 Future work
    \2 We usually have more than raw features. Interaction between raw and
    original features?
      \3 Example: For each cell, we may have a measure of the amounts of
      different proteins or transcripts there
    \2 How can you detect whether the bootstrapped feature extractors would be
    similar or not, without running so much computation?
    \2 How to deal with features learned at multiple scales? We can imagine
    sampling new cells within the same person, new people within the same
    population, ...
\end{outline}

\bibliographystyle{plain}
\bibliography{refs.bib}
\end{document}
