
\section{Data Analysis}

We illustrate the use of this methodology on a real data analysis example. These
spatial proteomics data\footnote{The data are
  \href{https://www.angelolab.com/mibi-data}{publicly available}} were reported
in the study \citep{keren2018structured} and describe the relationship between
the spatial organization of cancer tumors and the progression of the disease. In
a standard proteomics study, the expression levels for a set of proteins is
measured for a collection of cells, but the distances between cells is unknown.
In contrast, these data provide (1) for each patient, an image delineating cells
and (2) the protein expression levels associated with each cell in the images.

We will work only with the spatial cellular imagery, not the protein expression
levels. This allows us to study the mechanics of feature learning within the
images without having to worry about linking the expression and image data. What
we lose in terms of scientific interestingness we gain in implementation
simplicity. Our complete data are therefore 41 $2048 \times 2048$-dimensional
images, each taken from a separate patient. We associate each pixel with one of
7 categories of tumor and immune cell types.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{example_cells}
  \caption{Example patches of TNBC data. Each cell is shaded in by its cell
    type. Keratin+ and Mesenchymal-like cells are tumor cells, the rest are
    immune cells. Panels are ordered by $y_i$, the (log) fraction of cells they
    contain that belong to the tumor. The goal of the prediction algorithm in
    this illustrative example is to correctly place patches from new patients
    along this gradient, after having observed many patches and their
    corresponding $y_i$'s.}
  \label{fig:example_cells}
\end{figure}


To setup a prediction problem, we first split each image into $512 \times 512$
patches. These patches are our $x_{i}$. Patches from 32 of the patients are
reserved form feature learning. Four among these 32 are used as a validation
split, to tune parameters of the feature learning algorithms. As a response
variable, we use $y_{i} = \log\left(\frac{\#\{\text{Tumor cells in }x_{i}\}}{\#\{\text{Immune cells in }x_i\}}\right)$.

As a baseline, we compare against a ridge regression with pixelwise composition
features. Specifically, we train a model with $y$ as a response and the average
number of pixels belonging to each of the cell-type categories as a (length 7)
feature vector. This allows us to gauge whether the model has learned more
interesting features useful for counting cells, like cell size and boundaries,
rather than simply referring to raw pixel values. Indeed, we find that the
baseline achieves a test set performance of 1.58, which is noticeably worse than
the performances of models trained on aligned features
$\underaccent{\bar}{\mathbf{Z}}_{b}\left[I^{C}\right]$, reported in Figure
\ref{fig:performance}.

Stability curves associated with the learned features from the CNN, VAE, and RCF
models are shown in Figure \ref{fig:tnbc_stability}. Figure
\ref{fig:tnbc_features} can be used to interpret different feature dimensions.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{tnbc_selection_svd}
  \caption{Selection curves for features learned from the TNBC data. 50\% of
    the data were used for feature learning and the SVD was used for
    dimensionality reduction. Each curve is read as in Figure
    \ref{fig:selection_paths50}. The analogous paths using SCA alignment are
    given in the appendix. }
  \label{fig:tnbc_selection_svd}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{tnbc_important_features}
  \caption{Representation of samples according to some of the important learned
    feature dimensions, obtained using a CNN (a), RCF (b), and VAE (c). Glyphs
    are read as in Figure \ref{fig:embeddings-test}. To interpret these
    features, example patches are arranged according to these coordinates in
    Figure \ref{fig:embeddings-images}. Example unimportant feature dimensions
    are given in Supplementary Figure \ref{fig:tnbc_unimportant_features}.}
  \label{fig:tnbc_important_features}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{tnbc_imagegrid}
  \caption{}
  \label{fig:tnbc_important_features}
\end{figure}

data used in study

figure 1: data

reference -- baseline

interpretation

figure 2:

interpretation

figure 3:

interpretation
