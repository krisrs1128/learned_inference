
How should we perform statistical inference on nontabular data? One idea,
discussed in \citep{buhlmann2019comments}, is to first transform the data into
tabular form, taking advantage of modern feature learning algorithms. The point
is important enough to quote at length,

\begin{quote}
I would like to re-emphasize the importance of new sources of information.
Indeed, images, videos and audios are typically cheap devices to record data.
[The authors] do not mention recent progress with autoencoders
\citep{hinton2006reducing, vincent2010stacked}: when using such techniques, one
would again end up with numeric features which can then be used for further
downstream analysis using techniques from high-dimensional statistics or
statistical machine learning \citep{hastie2015statistical,
  buhlmann2011statistics}.
\end{quote}

Here, we explore this proposal in depth, illustrating how methods from
high-dimensional statistics can be used to study the inferential properties of
machine-generated features. Specifically, we present algorithms and
visualizations that can be used to characterize the statistical stability of
features learned from nontabular data sources. In the process, we also uncover
novel challenges particular to this new setting.

To ground the discussion, consider the following examples,

\begin{itemize}
\item Spatial Omics: In addition to measuring gene or protein expression at the
  cell level, it has become possible to study how expression varies spatially
  across a tissue \citep{lundberg2019spatial}. A variety of spatial features are
  thought to influence biological processes. For example, for some types of
  cancer, it is thought that the infiltration of tumors by immune cells
  expressing particular proteins can influence disease prognosis
  \citep{keren2018structured}.
\item Ecological and public health: Satellite imagery are now routinely
  integrated into ecological and public health projects, since they can capture
  important environmental features and are readily available globally
  \citep{jean2016combining, bondimapping}. These methods have been found to be effective
  proxies for otherwise resource-intensive collection methods, like
  on-the-ground surveys, opening up the possibility of more universal and easily
  updated monitoring.
\end{itemize}

In both cases, machine learning methods are key for extracting useful features
from novel sources of data. However, unlike many common machine learning
applications, the learned features here are subject to critical examination,
either to inform biological mechanisms or to ensure vulnerable populations are
not put at risk.

This question of how to perform inference on learned features is not a new one —
tests are available for the scores obtained in factor analysis \cite{rao1955estimation},
principal components can be bootstrapped \cite{diaconis1983computer}, and
confidence regions are available for exploratory projection pursuit
\cite{elguero1988confidence}. More recently, studies have investigated the use
of black-box predictions as features in downstream analysis
\citep{wang2020methods}.

However, for both the proteomics and satellite imagery examples presented above,
these methods can't be directly applied, because the raw data are not tabular.
Instead, features are typically automatically learned using deep learning. What
is new in this setting?

\begin{itemize}
\item Modern learned features are ``distributed'' \cite{mcclelland1986parallel}.
  This means that any pattern observed by the algorithm will be encoded by a
  large number of more elementary features, not any single feature specialized
  to that pattern. A deep learning algorithm is able to recognize a highway in a
  satellite image because it can merge evidence from across neurons (i.e., an
  elementary learned feature) that activate when particular color, shape, and
  edge features are present. This approach turns out to be much more effective
  than curating specialized features for many computational tasks, but it poses
  a challenge for human inspection.
\item From one run to the next, the learned features can change. This is unlike
  in principal components analysis, say, where the learned components are
  ordered in a natural way. If the deep learning features were more specialized,
  it might be possible to recognize the same feature across two runs, and then
  match them. However, the features are distributed, so it isn’t easy to say
  that any given neuron from the first run matches any other neuron(s) in the
  second.
\item It’s impractical to bootstrap methods that take hours to run, even if they
  could be done in parallel. Moreover, it’s unclear what information should be
  compared across bootstraps — the model parameters, the learned features, or
  summary statistics about the features.
\item Some form of sample-splitting must take place, to ensure that features are
  not evaluated using the same data that was used to learn them. However, it’s
  unclear how the splitting should be carried out. How much data should be used
  for feature learning, and how much for inference?
\end{itemize}

This work discusses these questions, proposing relevant definitions and
algorithms, examining their behavior through simulation, and illustrating their
use on a spatial proteomics dataset. Our basic takeaways are,

\begin{itemize}
\item While learned features are not interpretable when viewed in isolation,
  their associated feature subspaces often are. A feature learning algorithm may
  require a large number of elementary features in order to develop effective
  distributed representations, but the effective dimensionality of these
  representations is often small. These algorithms learn many, but highly
  correlated, features.
\item Given enough training data, learned feature subspaces are often stable
  from one run to the next, and this can be quantified using a Procrustes
  analysis. Unsupervised feature learning algorithms are typically more stable
  than supervised ones.
\item For problems where unsupervised feature learning is effective, a fast
  approximation to full deep model training, called the random convolutional
  features (RCF) model, can suffice for a feature stability analysis.
\item Inference is less data-greedy than feature learning, in the sense that
  when few samples are reserved for inference, stable features can still be
  identified. This is no longer the case when few samples are reserved for
  feature learning.
\end{itemize}

Section \ref{sec:psetup} provides a description of our problem setting. Section
\ref{sec:context} summarizes the key technical tools used in this study. We
present generic algorithms for measuring feature subspace stability in Section
\ref{sec:algorithms}, and we study its properties through a simulation in
Section \ref{sec:simulation}. We conclude in Section \ref{sec:dataset} with an
application to a spatial proteomics dataset.

\section{Problem Setup}
\label{sec:psetup}

Our goal is to characterize the stability of features that were algorithmically
derived from $n$ samples $x_i \in \mathcal{X}$. For example, each $x_{i}$ might
be a spatial proteomics measurement or a satellite image. They could also be
more general data types -- $x_i$ might be the audio recording for one of $n$
speakers, or the graph derived from one of $n$ molecules. Optionally, a vector
$\mathbf{y}\in \reals^{n}$ of responses associated with each observation will be
available. We denote the full set of available data by $\mathcal{D}$.

\begin{definition}
A \textit{feature learner} is a parameterized mapping $T\left(\cdot;
\theta\right): \mathcal{X} \to \reals^{L}$ which takes data from the raw input
domain $\mathcal{X}$ and represents it using a vector in $\reals^{L}$.
\end{definition}

For example, in the proteomics and satellite applications, we expect the learner
to transform a set of raw pixel intensities into a vector of features reflecting
biological or environmental properties of the imaged sample. The parameter
$\theta$ is estimated from data, typically through an optimization problem,
\begin{align*}
  \hat{\theta} := \arg\min_{\theta \in \Theta} \mathcal{L}\left(\mathcal{D}, T\left(\cdot; \theta\right)\right)
\end{align*}
for some loss function $\mathcal{L}$. In an unsupervised feature learner,
candidates $\theta \in \Theta$ are functions of $x_{1}, \dots, x_{n}$ alone. For
a supervised feature learner, the class includes functions of both
$x_{1}, \dots, x_{n}$ and $\mathbf{y}$. To simplify notation, we will write
$z_{i} = T\left(x_{i}; \hat{\theta}\right) \in
\reals^{L}$ to denote the learned features associated with the $i^{th}$
observation.

A first attempt might try to assign a stability score to each of the $L$
coordinates of $z$. An investigator would then have confidence that, if data
were sampled again from the same population, and if features were extracted by
the same black box, then the features with high stability scores would reappear
in the new analysis. The essential challenge is that the learned features are
not the same from one run to the next; the $l^{th}$ learned feature from run 1
need not have any relationship with the $l^{th}$ feature from run 2.

To address this issue, we distinguish between two notions of stability, which we
call feature subspace and selection stability, respectively. The idea of
subspace stability is that, even if there is no direct correspondence between
learned features across runs, they may all reflect the same underlying latent
features. Different runs of the feature learning algorithm return different
bases for nearly the same subspace. To make this more precise, suppose that the
$b^{th}$ run of the feature learning algorithm produces,

\begin{align}
\mathbf{Z}_{b} &= \begin{pmatrix}
z^{b}_{1} \\
\vdots \\
z^{b}_{n}
\end{pmatrix} \in \reals^{n \times L}
\end{align}

and define an alignment function $\mathcal{A}$ which takes learned to aligned
features,
\begin{align*}
\mathcal{A}: \mathbf{Z}_{1}, \dots, \mathbf{Z}_{B} \to \mathbf{M}, \left(\underaccent{\bar}{\mathbf{Z}}_{1}, \dots, \underaccent{\bar}{\mathbf{Z}}_{B}\right).
\end{align*}

We think of $\mathbf{M} \in \reals^{n \times K}$ as the average of all $B$
representations and $\underaccent{\bar}{\mathbf{Z}}_{b} \in \reals^{n \times K}$
as the version of the $b^{th}$ learned representation after they have been put
into a common coordinate system. In this work, $\mathcal{A}$ is just a
Procrustes analysis. With this notation, we can now define subspace stability.
\begin{definition}
The \textit{subspace stability} of $B$ learned representations $\mathbf{Z}_{1},
\dots, \mathbf{Z}_{B}$ with respect to an alignment function $\mathcal{A}$ is
the average distance between the aligned features and $\mathbf{M}$,
\begin{align*}
FSS_{\mathcal{A}}\left(\mathbf{Z}_{1}, \dots, \mathbf{Z}_{B}\right) &= \frac{1}{B} \sum_{b = 1}^{B} \|\underaccent{\bar}{\mathbf{Z}}_{b} - \mathbf{M}\|^{2}_{2} \\
\text{where } \mathbf{M}, \left(\underaccent{\bar}{\mathbf{Z}}_{1}, \dots, \underaccent{\bar}{\mathbf{Z}}_{B}\right) &= \mathcal{A}\left(\mathbf{Z}_{1}, \dots, \mathbf{Z}_{B}\right)
\end{align*}
\end{definition}

By selection stability, we mean that a given aligned feature is repeatedly
discovered by a model selection procedure. At this point, the features can be
thought of as fixed; we are back on more familiar inferential ground. That is,
let $\mathcal{S}$ be a selection function, which takes
$\underaccent{\bar}{\mathbf{Z}}_{b}$ and a response $\mathbf{y}$ and returns a
subset $S_{b} \subseteq \{1, \dots, K\}$ of features important for predicting
$\mathbf{y}$.

\begin{definition}
The \textit{selection stability} of the $k^{th}$ aligned feature with respect to
the selection $\mathcal{S}$ is the
fraction
\begin{align*}
SS_{\mathcal{S}}^{k}\left(\underaccent{\bar}{\mathbf{Z}}_{1}, \dots, \underaccent{\bar}{\mathbf{Z}}_{B}\right) &= \frac{1}{B}\sum_{b = 1}^{B} \indic{k \in \mathcal{S}\left(\underaccent{\bar}{\mathbf{Z}}_{b}, \mathbf{y}\right)}.
\end{align*}
\end{definition}
