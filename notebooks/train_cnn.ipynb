{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from addict import Dict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stability.models.cnn import CBRNet, cnn_loss\n",
    "import stability.data as sd\n",
    "import stability.train as st\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "root_dir = pathlib.Path(os.environ[\"ROOT_DIR\"])\n",
    "opts = Dict(yaml.safe_load(open(root_dir / \"conf/train_cnn.yaml\", \"r\")))\n",
    "\n",
    "features_dir = data_dir / opts.organization.features_dir\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "writer = SummaryWriter(features_dir / \"logs\")\n",
    "writer.add_text(\"conf\", json.dumps(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model = CBRNet()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=opts.train.lr)\n",
    "if opts.train.checkpoint is not None:\n",
    "    model.load_checkpoint(data_dir / opts.train.checkpoint)\n",
    "\n",
    "# build loaders\n",
    "splits = pd.read_csv(data_dir / opts.organization.splits)\n",
    "resample_ix = pd.read_csv(data_dir / opts.bootstrap.path)\n",
    "\n",
    "paths = {\n",
    "    \"train\": splits.loc[splits.split == \"train\", \"path\"].values,\n",
    "    \"dev\": splits.loc[splits.split == \"dev\", \"path\"].values,\n",
    "    \"test\": splits.loc[splits.split == \"test\", \"path\"].values\n",
    "}\n",
    "\n",
    "\n",
    "def initialize_loader(paths, data_dir, opts, **kwargs):\n",
    "    cell_data = sd.CellDataset(paths, data_dir / opts.organization.xy, data_dir)\n",
    "    return DataLoader(cell_data, batch_size=opts.train.batch_size, **kwargs)\n",
    "\n",
    "loaders = {}\n",
    "loaders[\"train\"] = initialize_loader(paths[\"train\"][resample_ix][0], data_dir, opts, shuffle=True)\n",
    "loaders[\"features\"] = initialize_loader(paths[\"train\"], data_dir, opts)\n",
    "loaders[\"dev\"] = initialize_loader(paths[\"dev\"], data_dir, opts)\n",
    "loaders[\"test\"] = initialize_loader(paths[\"test\"], data_dir, opts)\n",
    "\n",
    "# train\n",
    "out_paths = [\n",
    "    data_dir / opts.organization.features_dir, \n",
    "    data_dir / opts.organization.metadata,\n",
    "    data_dir / \"model_final.pt\"\n",
    "]\n",
    "st.train(model, optim, loaders, opts, out_paths, writer, cnn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "li2",
   "language": "python",
   "name": "li2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
