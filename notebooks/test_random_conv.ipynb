{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from addict import Dict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stability.models.cnn import CBRNet\n",
    "import stability.models.random_features as rcf\n",
    "from stability.data import CellDataset\n",
    "import stability.train as st\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "root_dir = pathlib.Path(os.environ[\"ROOT_DIR\"])\n",
    "opts = Dict(yaml.safe_load(open(root_dir / \"conf/cnn15.yaml\", \"r\")))\n",
    "\n",
    "features_dir = data_dir / opts.organization.features_dir\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "writer = SummaryWriter(features_dir / \"logs\")\n",
    "writer.add_text(\"conf\", json.dumps(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build loaders\n",
    "splits = pd.read_csv(data_dir / opts.organization.splits)\n",
    "resample_ix = pd.read_csv(data_dir / opts.bootstrap.path)\n",
    "\n",
    "paths = {\n",
    "    \"train\": splits.loc[splits.split == \"train\", \"path\"].values,\n",
    "    \"dev\": splits.loc[splits.split == \"dev\", \"path\"].values,\n",
    "    \"test\": splits.loc[splits.split == \"test\", \"path\"].values\n",
    "}\n",
    "\n",
    "\n",
    "def initialize_loader(paths, data_dir, opts, **kwargs):\n",
    "    cell_data = CellDataset(paths, data_dir / opts.organization.xy, data_dir)\n",
    "    return DataLoader(cell_data, batch_size=opts.train.batch_size, **kwargs)\n",
    "\n",
    "loaders = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [data_dir / s for s in paths[\"train\"]]\n",
    "patches = rcf.random_patches(p, k = 1024)\n",
    "model = rcf.WideNet(torch.Tensor(patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches2 = torch.Tensor(rcf.random_patches(p, 10))\n",
    "D = model(patches2).detach()\n",
    "D = D.squeeze()\n",
    "max_ix = np.where(D[0, :] == D[0, :].max())[0][0]\n",
    "print(max_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(np.transpose(patches[max_ix], (1, 2, 0)))\n",
    "plt.show()\n",
    "plt.imshow(np.transpose(patches2[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[\"train\"] = initialize_loader(paths[\"train\"][resample_ix][0], data_dir, opts, shuffle=True)\n",
    "loaders[\"features\"] = initialize_loader(paths[\"train\"], data_dir, opts)\n",
    "loaders[\"dev\"] = initialize_loader(paths[\"dev\"], data_dir, opts)\n",
    "loaders[\"test\"] = initialize_loader(paths[\"test\"], data_dir, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loaders[\"train\"]\n",
    "l.dataset.root\n",
    "\n",
    "i = 0\n",
    "D = []\n",
    "for x, _ in l:\n",
    "    print(i)\n",
    "    D.append(model(x))\n",
    "    i += 1\n",
    "    if i > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.cat(D).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = pd.read_csv(\"/Users/kris/Documents/stability_data/Xy.csv\")\n",
    "y = xy.iloc[resample_ix.iloc[0, :]][\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "ridge_model = lm.Ridge()\n",
    "y = (y - y.mean()) / y.std()\n",
    "ridge_model.fit(X = D.detach(), y = y[:len(D)])\n",
    "ridge_model.coef_\n",
    "y_hat = ridge_model.predict(X = D.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y[:len(D)], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "li2",
   "language": "python",
   "name": "li2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
