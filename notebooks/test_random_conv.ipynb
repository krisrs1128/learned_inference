{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from addict import Dict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stability.models.cnn import CBRNet\n",
    "from stability.data import CellDataset\n",
    "import stability.train as st\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = pathlib.Path(os.environ[\"DATA_DIR\"])\n",
    "# root_dir = pathlib.Path(os.environ[\"ROOT_DIR\"])\n",
    "data_dir = pathlib.Path(\"/Users/kris/Documents/stability_data_big/\")\n",
    "root_dir = pathlib.Path(\"/Users/kris/Desktop/conceptual/learned_inference/\")\n",
    "opts = Dict(yaml.safe_load(open(root_dir / \"conf/train.yaml\", \"r\")))\n",
    "\n",
    "features_dir = data_dir / opts.organization.features_dir\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "writer = SummaryWriter(features_dir / \"logs\")\n",
    "writer.add_text(\"conf\", json.dumps(opts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build loaders\n",
    "splits = pd.read_csv(data_dir / opts.organization.splits)\n",
    "resample_ix = pd.read_csv(data_dir / opts.bootstrap.path)\n",
    "\n",
    "paths = {\n",
    "    \"train\": splits.loc[splits.split == \"train\", \"path\"].values,\n",
    "    \"dev\": splits.loc[splits.split == \"dev\", \"path\"].values,\n",
    "    \"test\": splits.loc[splits.split == \"test\", \"path\"].values\n",
    "}\n",
    "\n",
    "\n",
    "def initialize_loader(paths, data_dir, opts, **kwargs):\n",
    "    cell_data = CellDataset(paths, data_dir / opts.organization.xy)\n",
    "    return DataLoader(cell_data, batch_size=opts.train.batch_size, **kwargs)\n",
    "\n",
    "loaders = {}\n",
    "#loaders[\"train\"] = initialize_loader(paths[\"train\"][resample_ix][0], data_dir, opts, shuffle=True)\n",
    "#loaders[\"features\"] = initialize_loader(paths[\"train\"], data_dir, opts)\n",
    "#loaders[\"dev\"] = initialize_loader(paths[\"dev\"], data_dir, opts)\n",
    "#loaders[\"test\"] = initialize_loader(paths[\"test\"], data_dir, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stability.models.random_features as rcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = torch.randn(100, 3, 6, 6)\n",
    "model = rcf.WideNet(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 3, 32, 32)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)[:, :, 0, 0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(patches)[:, :, 0, 0].detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "li2",
   "language": "python",
   "name": "li2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
