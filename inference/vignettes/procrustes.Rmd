---
title: "Procrustes and Varimax Alignment"
output: html_notebook
params:
  model_prefix: "vae15"
  layer: "mu"
  ncomp: 10
---

```{r libraries}
library("dplyr")
library("ggplot2")
library("glmnet")
library("inference")
library("purrr")
library("readr")
library("reshape2")
library("reticulate")
library("stringr")
theme_set(theme_bw())
```
First we read in all the relevant data.

```{r read_meta}
# unzip raw experimental output
data_dir <- "/Users/kris/Documents/stability_outputs/"
paths <- c(
  file.path(data_dir, sprintf("%s.yaml_0.tar.gz", params$model_prefix)),
  file.path(data_dir, sprintf("%s.yaml_1.tar.gz", params$model_prefix)),
  file.path(data_dir, sprintf("%s.yaml_2.tar.gz", params$model_prefix)),
  file.path(data_dir, sprintf("%s.yaml_3.tar.gz", params$model_prefix)),
  file.path(data_dir, sprintf("%s.yaml_4.tar.gz", params$model_prefix))
)
untar_all(paths, data_dir = data_dir)

# read in response data and input image paths
output_dirs <- map(paths, ~ file.path(data_dir, tools::file_path_sans_ext(basename(.x))))
Xy <- read_csv(file.path(output_dirs[1], "Xy.csv"))
metadata <- map(output_dirs, ~ read_csv(file.path(.x, params$model_prefix, "metadata.csv")))
subsets <- map(output_dirs, ~ read_csv(file.path(.x, params$model_prefix, "features", "subset.csv")))
names(subsets) <- output_dirs
```
Next, let's identify the paths to all the activation numpy files. This involves

* merging all the `metadata.csv` files produced by individual runs
* annotating the bootstrap number associated with each run
* giving absolute and relative paths to the data

```{r parse_metadata}
metadata <- map(output_dirs, ~ cbind(abs_path = .x, read_csv(file.path(.x, params$model_prefix, "metadata.csv")))) %>%
  map_dfr(~ .x %>% 
      mutate(
        model = str_replace(out_path, "(.+)stability_data/(.+)/features(.+)", "\\2"),
        rel_path = str_replace(out_path, "(.+)stability_data/(.+)", "\\2")
        )
  ) %>%
  mutate(
    bootstrap = str_replace(abs_path, "(.+)yaml_([0-9]+).tar", "\\2"),
    bootstrap = as.numeric(bootstrap),
    abs_path = file.path(abs_path, rel_path),
    source = str_replace(abs_path, "(.+)(tar)(.+)", "\\1\\2")
  ) %>%
  select(abs_path, source, model, bootstrap, epoch, layer)
```


Now, we'll read in the actual activations associated with each of the numpy
arrays referenced in the metadata file.

```{r read_acts}
np <- import("numpy")
acts_ <- metadata %>%
  filter(epoch == "best", layer == params$layer) %>%
  .[["abs_path"]] %>%
  unique()
acts <- map(acts_, ~ data.frame(np$load(.x)))
subsets_ <- map(subsets, ~ rename(., c("ix" = "X1", "rel_path" = "path")))
acts <- map2_dfr(subsets_, acts, cbind, .id = "source") %>%
  left_join(metadata %>% select(source, bootstrap) %>% unique())
```
```{r activation_histo}
macts <- acts %>%
  select("rel_path", starts_with("X")) %>%
  melt(id.vars = "rel_path")
ggplot(macts) +
  geom_histogram(aes(x = value), bins = 200)
ggsave(sprintf("%s_activation_histogram.png", params$model_prefix))
```

First, we'll get the projected scores, using MultiCCA.

```{r multicca}
acts_splits <- acts %>%
  split(.$bootstrap)
  
x_list <- acts_splits %>%
  map(~ .x %>% select(starts_with("X")) %>% as.matrix())

png(sprintf("%s_svd_eigs.png", params$model_prefix))
plot(svd(x_list[[1]])$d)
dev.off()

for (i in seq_along(x_list)) {
  if (grepl("vae", params$model_prefix)) break
  x_list[[i]] <- asinh(x_list[[i]])
  for (j in seq_len(ncol(x_list[[i]]))) {
    x_list[[i]][, j] <- x_list[[i]][, j] + runif(nrow(x_list[[i]]), -0.2, 0.2)
  }
}
```

```{r}
x_scores <- map(x_list, ~ { 
  svd_res <- svd(.)
  svd_res$u[, 1:10] %*% diag(svd_res$d[1:10])
})

x_align <- procrustes(x_scores)$x_align
x_align <- lapply(seq_len(dim(x_align)[3]), function(i) x_align[,, i])
plot(x_align[[3]])
points(x_align[[2]], col = "red")
```



```{r}
scores <- c(
  map2(x_list[grepl("dev", names(x_list))], cca_res$ws, ~ .x %*% .y),
  map2(x_list[grepl("test", names(x_list))], cca_res$ws, ~ .x %*% .y),
  map2(train_list, cca_res$ws, ~ .x %*% .y)
)

for (i in seq_along(scores)) {
  colnames(scores[[i]]) <- paste0("dim", 1:params$ncomp)
}

scores <- map2_dfr(acts_splits, scores, ~ cbind(.x %>% select(-starts_with("X")), .y)) %>%
  left_join(Xy, c("rel_path" = "path")) 
plot_data <- scores %>%
  melt(measure.vars = paste0("dim", 1:params$ncomp), variable.name = "dim") %>%
  arrange(ix) %>%
  filter(ix %in% sample(max(scores$ix), 3000))
plot_data$split <- factor(plot_data$split, levels = c("train", "dev", "test"))
```

Before we can plot them, we need to merge them into a data.frame and tidy.

```{r edge_data}
centroids <- plot_data %>%
  group_by(dim, rel_path, split, y) %>%
  summarise(mean = mean(value)) %>%
  mutate(dim = paste0("mean", dim)) %>%
  dcast(rel_path + split + y ~ dim, value.var = "mean")

edge_data <- plot_data %>%
  dcast(bootstrap + rel_path + split + y ~ dim, value.var = "value") %>%
  split(.$bootstrap) %>%
  map_dfr(~ .x %>% left_join(centroids))

head(edge_data)
```

```{r, embedding_plot, fig.width = 8}
ggplot(edge_data) +
  geom_point(
    data = centroids,
    aes(x = meandim3, y = meandim2, col = y),
    alpha = 0.5, size = 0.8
    ) +
  geom_point(
    aes(x = dim3, y = dim2, col = y),
    size = 0.9, alpha = 0.3
  ) +
  geom_segment(
    aes(x = dim3, xend = meandim3, y = dim2, yend = meandim2, col = y),
    size = 0.3, alpha = 0.8
  ) +
  coord_fixed(1) +
  facet_grid(. ~ split) +
  scale_color_viridis_c() +
  theme(legend.position = "bottom")
ggsave(sprintf("embeddings_%s.png", params$model_prefix))
```

```{r stability_baseline}
xy <- scores %>%
  split(., list(.$bootstrap, .$split)) %>%
  map(~ subset_matrices(., paste0("dim", 1:params$ncomp)))

for (b in seq_along(xy)) {
  fit <- glmnet(x = xy[[b]]$X, y = xy[[b]]$y)
  y_hat <- predict(fit, newx = xy[[b]]$X, type = "response")
  plot(cv.glmnet(xy[[b]]$X, xy[[b]]$y))
  png(sprintf("y_vs_y_hat-%s-%s.png", params$model_prefix, names(xy)[b]))
  plot(xy[[b]]$y, y_hat[, dim(y_hat)[2]], col = rgb(0, 0, 0, 0.6), cex = 0.5, main = names(xy)[b])
  abline(a = 0, b = 1, col = "red")
  dev.off()
}
```
Now let's run stability selection on each split and bootstrap sample separately.

```{r stability_selection}
lambda <- 2 ^ seq(-1, -8, length.out = 20)
selection_data <- map(xy, ~ stability_selection(.x$X, .x$y, B = 250, lambda = lambda))
pi_hat <- map_dfr(selection_data, ~ melt(t(.x$Pi), varnames = c("lambda", "j")), .id = "run") %>%
  tidyr::separate(run, c("bootstrap", "split"))
pi_hat$j <- as.integer(pi_hat$j) - 1
pi_hat$lambda <- lambda[pi_hat$lambda]
```

Below, we're plotting the number of times each feature is selected by the 250
lasso's above, as a function of $\lambda$.

```{r stability_plot, fig.height = 3, fig.width = 8}
pi_hat <- pi_hat %>%
  tidyr::unite(jb, j, bootstrap, split, remove = FALSE)
pi_hat$split <- factor(pi_hat$split, levels = c("train", "dev", "test"))
ggplot(pi_hat %>% filter(j < 17)) +
  geom_line(aes(x = lambda, y = value, col = bootstrap, group = jb, linetype = split)) +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(trans = ggforce::trans_reverser('log10')) +
  facet_wrap(~ j, ncol = 6) +
  theme(legend.position = "bottom")
ggsave(sprintf("selection_paths_%s.png", params$model_prefix))
```
What is the average correlation between selected features and the underlying
generative process?

```{r, correlation_diagram, fig.width = 8, fig.height = 5}
selections <- pi_hat %>% 
  filter(lambda > 0.03, lambda < 0.1) %>%
  group_by(j, split) %>%
  summarise(selection = mean(value)) %>%
  mutate(dim = paste0("dim", j)) %>%
  select(-j)
  
scores_mat <- scores %>%
  split(.$split)

mcor <- list()
for (i in seq_along(scores_mat)) {
  scores_i <- scores_mat[[i]] %>%
    select(starts_with("dim"), starts_with("X")) %>%
    as.matrix()
  mcor[[i]] <- melt(cor(scores_i), varnames = c("dim", "feature")) %>%
    filter(!(feature %in% paste0("dim", 1:params$ncomp))) %>%
    filter(dim %in% paste0("dim", 1:params$ncomp))
  mcor[[i]]$split <- scores_mat[[i]]$split[1]
}

mcor <- do.call(rbind, mcor) %>%
  left_join(selections) %>%
  mutate(dim = gsub("dim", "", dim))
mcor$dim <- factor(mcor$dim, levels = 1:10)
  
ggplot(mcor) +
  geom_hline(yintercept = 0) +
  geom_point(aes(x = feature, y = value, col = selection, shape = split)) +
  facet_wrap(~ dim) +
  scale_color_viridis_c() +
  theme(
    axis.text.x = element_text(angle = 90, size = 8),
    legend.position = "bottom"
  )
ggsave(sprintf("%s_correlation_diagram.png", params$model_prefix))
```


```{r correlation_heatmap}
scores_mat <- scores %>%
  select(starts_with("dim"), starts_with("X")) %>%
  as.matrix()
png(sprintf("%s_correlation_heatmap.png", params$model_prefix))
heatmap(cor(scores_mat))
dev.off()
```

```{r remove_unzipped}
paths0 <- gsub(".gz", "", paths)
unlink(paths0)
```

