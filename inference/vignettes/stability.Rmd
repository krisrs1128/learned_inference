---
title: Stability Analysis
output: html_notebook
params:
  basename: "full_best.npy"
  data_dir: "/Users/kris/Documents/tmp//"
  model_prefix: "tnbc_rcf"
  ncomp: 10
  python_path: "/usr/bin/python3"
  save_dir: "/Users/kris/Desktop/conceptual/learned_inference/notes/figures"
  sca: FALSE
  tiles_dir: "/Users/kris/Documents/tiles_dir"
---

```{r libraries}
library("dplyr")
library("epca")
library("ggplot2")
library("glmnet")
library("inference")
library("purrr")
library("readr")
library("reshape2")
library("reticulate")
library("stringr")
theme_set(theme_bw())

dpath <- function(x, s) {
  read_csv(file.path(x, paste0(s, collapse = "/")), col_types = cols())
}
```
First we read in all the relevant data.

```{r read_meta}
# unzip raw experimental output
data_dir <- params$data_dir
paths <- list.files(data_dir, sprintf("%s.+tar.gz", params$model_prefix), full.names = TRUE)
untar_all(paths, data_dir = data_dir)

# read in response data and input image paths
output_dirs <- map(paths, ~ file.path(data_dir, tools::file_path_sans_ext(basename(.x))))
Xy <- dpath(params$tiles_dir, "Xy.csv")
metadata <- map(output_dirs, ~ dpath(.x, "layers.csv"))
subsets <- map(output_dirs, ~ dpath(.x, c("features", "subset.csv")))
names(subsets) <- output_dirs
```
Next, let's identify the paths to all the activation numpy files. This involves

* merging all the `layers.csv` files produced by individual runs)
* annotating the bootstrap number associated with each run
* giving absolute and relative paths to the data

```{r parse_metadata}
metadata <- map(output_dirs, ~ cbind(abs_path = .x, dpath(.x, "layers.csv"))) %>%
  map_dfr(~ .x %>%
      mutate(
        model = str_replace(out_path, "(.+)stability_data/(.+)/features(.+)", "\\2"),
        rel_path = str_replace(out_path, "(.+)stability_data/(.+)", "\\2")
        )
  ) %>%
  mutate(
    bootstrap = str_replace(abs_path, "(.+)yaml_([0-9]+).tar", "\\2"),
    bootstrap = as.numeric(bootstrap),
    abs_path = file.path(abs_path, rel_path),
    source = str_replace(abs_path, "(.+)(tar)(.+)", "\\1\\2")
  ) %>%
  dplyr::select(abs_path, rel_path, source, model, bootstrap, epoch, layer)
```


Now, we'll read in the actual activations associated with each of the numpy
arrays referenced in the metadata file.

```{r read_acts}
use_python(params$python_path)
np <- import("numpy")
acts_ <- metadata %>%
  filter(basename(rel_path) == params$basename) %>%
  pull(abs_path) %>%
  unique()
acts <- map(acts_, ~ data.frame(np$load(.)))
subsets_ <- map(subsets, ~ dplyr::rename(., c("ix" = "X1", "rel_path" = "path")))

acts <- map2_dfr(subsets_, acts, cbind, .id = "source") %>%
  left_join(metadata %>% select(source, bootstrap) %>% unique())


if (!("y" %in% colnames(acts))) {
  acts <- acts %>%
    left_join(Xy %>% select(path, y), c("rel_path" = "path"))
}
```

```{r activation_histo}
macts <- acts %>%
  select("rel_path", starts_with("X")) %>%
  melt(id.vars = "rel_path")
ggplot(macts) +
  geom_histogram(aes(x = value), bins = 200)

save_dir <- file.path(params$save_dir, params$model_prefix)
dir.create(save_dir, recursive = TRUE)
ggsave(file.path(save_dir, "activation_histogram.png"))
```

```{r multicca}
acts_splits <- acts %>%
  split(.$bootstrap)

x_list <- acts_splits %>%
  map(~ .x %>% select(matches("X[0-9]+"))) %>%
  map(~ .x %>% select_if(~ sum(is.na(.)) == 0)) %>% # different runs can have different # cols
  map(as.matrix)

png(file.path(save_dir, "svd_eigs.png"))
plot(svd(x_list[[1]])$d)
dev.off()

for (i in seq_along(x_list)) {
  if (grepl("vae", params$model_prefix)) break
  x_list[[i]][is.na(x_list[[i]])] <- 0
  sigma_sqs <- apply(x_list[[i]], 2, var)
  x_list[[i]][, sigma_sqs == 0] <-  runif(length(x_list[[i]][, sigma_sqs == 0]))
  x_list[[i]] <- asinh(x_list[[i]])
}
```

```{r}
if (params$sca) {
  sparse_approx <- map(x_list, ~ sca(., k = max(params$ncomp, 20)))
} else {
  sparse_approx <- map(x_list, ~ princomp(., scale = TRUE))
}
```

```{r}
pres <- sparse_approx %>%
  map(~ .$scores[, 1:params$ncomp]) %>%
  procrustes(0.005)
M <- pres$M
scores <- pres$x_align
scores <- lapply(seq_len(dim(scores)[3]), function(i) scores[,, i]) # split last dimension across list

feature_stability <- map(scores, ~ mean( (.x - M) ^ 2)) %>%
  unlist() %>%
  mean()
fss <- data.frame(
  model = params$model_prefix,
  ncom = params$ncomp,
  sca = params$sca,
  basename = params$basename,
  feature_stability = feature_stability
)
write_csv(fss, file.path(save_dir, "feature_stability.csv"))
```

```{r}
for (i in seq_along(scores)) {
  colnames(scores[[i]]) <- paste0("dim", 1:params$ncomp)
}

scores <- map2_dfr(acts_splits, scores, ~ cbind(.x %>% select(-starts_with("X")), .y))
plot_data <- scores %>%
  melt(measure.vars = paste0("dim", 1:params$ncomp), variable.name = "dim")
plot_data$split <- factor(plot_data$split, levels = c("train", "dev", "test"))
```

Before we can plot them, we need to merge them into a data.frame and tidy.

```{r edge_data}
centroids <- plot_data %>%
  group_by(dim, rel_path, split, y) %>%
  summarise(mean = mean(value)) %>%
  mutate(dim = paste0("mean", dim)) %>%
  dcast(rel_path + split + y ~ dim, value.var = "mean")

edge_data <- plot_data %>%
  dcast(bootstrap + rel_path + split + y ~ dim, value.var = "value") %>%
  split(.$bootstrap) %>%
  map_dfr(~ .x %>% left_join(centroids))

sca_label <- ifelse(params$sca, "sca", "svd")
write_csv(centroids, file.path(save_dir, sprintf("centroids_%s.csv", sca_label)))
write_csv(edge_data, file.path(save_dir, sprintf("edge_data_%s.csv", sca_label)))
```

```{r}
edge_dists <- edge_data %>%
  mutate(D = sqrt((dim1 - meandim1) ^ 2 + (dim2 - meandim2) ^ 2 + (dim3 - meandim3) ^ 2)) %>%
  select(split, D)

ggplot(edge_dists) +
  geom_histogram(aes(x = log(D), fill = split), bins = 50) +
  scale_color_brewer(palette = "Set2") +
  facet_wrap(~split, scale = "free_y")
write_csv(edge_dists, file.path(save_dir, sprintf("edge_dists_%s.csv", sca_label)))
```

```{r stability_baseline}
xy <- scores %>%
  split(., list(.$bootstrap, .$split)) %>%
  map(~ subset_matrices(., paste0("dim", 1:params$ncomp)))

for (b in seq_along(xy)) {
  fit <- glmnet(x = xy[[b]]$X, y = xy[[b]]$y)
  y_hat <- predict(fit, newx = xy[[b]]$X, type = "response")

  # glmnet plots
  plot(cv.glmnet(xy[[b]]$X, xy[[b]]$y))
  plot(xy[[b]]$y, y_hat[, dim(y_hat)[2]], col = rgb(0, 0, 0, 0.6), cex = 0.5, main = names(xy)[b])
}
```
Now let's run stability selection on each split and bootstrap sample separately.

```{r stability_selection}
lambda <- 2 ^ seq(-1, -8, length.out = 20)
selection_data <- map(xy, ~ stability_selection(.x$X, .x$y, B = 250, lambda = lambda))
pi_hat <- map_dfr(selection_data, ~ melt(t(.x$Pi), varnames = c("lambda", "j")), .id = "run") %>%
  tidyr::separate(run, c("bootstrap", "split"))
pi_hat$j <- as.integer(pi_hat$j) - 1
pi_hat$lambda <- lambda[pi_hat$lambda]
```

Below, we're plotting the number of times each feature is selected by the 250
lasso's above, as a function of $\lambda$.

```{r stability_plot, fig.height = 3, fig.width = 8}
pi_hat <- pi_hat %>%
  tidyr::unite(jb, j, bootstrap, split, remove = FALSE)
pi_hat$split <- factor(pi_hat$split, levels = c("train", "dev", "test"))
ggplot(pi_hat %>% filter(j > 0)) +
  geom_line(aes(x = log(lambda), y = value, col = split, group = jb)) +
  scale_color_brewer(palette = "Set2") +
  scale_x_reverse() +
  labs(
    x = expression(log(lambda)),
    y = expression(hat(Pi)^{b}~(lambda))
  ) +
  scale_y_continuous(breaks = c(0.1, 0.5, 0.9)) +
  facet_wrap(~ j, ncol = 5) +
  theme(
    legend.position = "bottom",
    panel.grid.minor = element_blank()
  )
ggsave(file.path(save_dir, sprintf("selection_paths_%s.png", sca_label)))
write_csv(pi_hat, file.path(save_dir, sprintf("pi_hat_%s.csv", sca_label)))
```
What is the average correlation between selected features and the underlying
generative process?

```{r, correlation_data, fig.width = 8, fig.height = 5}
lambda_thr <- lambda[8]

selections <- pi_hat %>%
  filter(lambda == lambda_thr) %>%
  group_by(j, split) %>%
  summarise(selection = mean(value)) %>%
  mutate(dim = paste0("dim", j)) %>%
  select(-j)

scores_mat <- scores %>%
  left_join(Xy %>% select(path, starts_with("X")), c("rel_path" = "path")) %>%
  split(., list(.$split, .$bootstrap))

cca_data <- list()
for (i in seq_along(scores_mat)) {
  scores_i <- scores_mat[[i]] %>%
    select(starts_with("dim"), starts_with("X")) %>%
    as.matrix()
  scores_i[is.na(scores_i)] <- 0
  
  dim_i <- scores_mat[[i]] %>%
    select(starts_with("dim")) %>%
    as.matrix()
  x_i <- scores_mat[[i]] %>%
    select(starts_with("X")) %>%
    as.matrix()
  x_i[is.na(x_i)] <- 0

  rhos <- cancor(dim_i, x_i)$cor
  cca_data[[i]] <- data.frame(
    k = seq_along(rhos),
    split = scores_mat[[i]]$split[1],
    bootstrap = scores_mat[[i]]$bootstrap[1],
    rho = rhos
  )
}
```

```{r}
cca_data <- bind_rows(cca_data)
ggplot(cca_data) +
  geom_point(aes(x = k, y = rho, col = split))
write_csv(cca_data, file.path(save_dir, sprintf("cca_data_%s.csv", sca_label)))
```
```{r correlation_heatmap}
scores_mat <- scores %>%
  select(starts_with("dim"), starts_with("X")) %>%
  as.matrix()
png(file.path(save_dir, sprintf("correlation_heatmap_%s.png", sca_label)))
cols <- c("#C51B7D", "#CC358B", "#D35099", "#DA6BA7", "#E181B5", "#E693C2", "#ECA6CF", "#F1B7DA", "#F5C4E1", "#F8D0E7", "#FCDCED", "#F8E4E8", "#F1EADF", "#EAF0D6", "#E2F3C9", "#D4EDB4", "#C7E79E", "#B9E189", "#A9D774", "#99CC60", "#88C24C", "#78B63C", "#6AAA33", "#5B9E2A", "#4D9221")
heatmap(cor(scores_mat), asp = 1, col = cols)
dev.off()
```

```{r}
pis <- seq(.4, 1, by = 0.05)
selections <- list()
for (i in seq_along(pis)) {
  selections[[i]] <- pi_hat %>%
    filter(j != 0) %>% # ignore intercept term
    filter(value > pis[i], lambda == lambda_thr) %>%
    group_by(split, bootstrap) %>%
    summarise(n_selected = n()) %>%
    mutate(pi_thr = pis[i])
}

selections <- bind_rows(selections) %>%
  group_by(split, pi_thr) %>%
  summarise(
    min = min(n_selected),
    max = max(n_selected),
    median = median(n_selected)
  )

selections$model <- str_extract(params$model_prefix, "[A-z]+")
selections$train_perc <- as.numeric(str_extract(params$model_prefix, "[0-9]+"))
selections$sca <- params$sca
write_csv(selections, file.path(save_dir, sprintf("selections_%s.csv", sca_label)))
```
In case we want to follow-up any of these analysis, we can look at these
RData's.

```{r}
save.image(file.path(params$save_dir, sprintf("stability_%s.RData", sca_label)))
```
